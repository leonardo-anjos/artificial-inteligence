{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso de Bibliotecas Python\n",
    "\n",
    "Existem várias bibliotecas que podem ser utilizadas para realizar análise de sentimento e emoção. Vamos conhecer algumas delas:\n",
    "\n",
    "- **TextBlob** (https://textblob.readthedocs.io)\n",
    "- **NLTK** (https://www.nltk.org/)\n",
    "- **Pattern** (https://www.clips.uantwerpen.be/pages/pattern-en#sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Sentimento com TextBlob\n",
    "\n",
    "**APRESENTAÇÃO**:\n",
    "\n",
    "O TextBlob visa fornecer acesso a operações comuns de processamento de texto através de uma interface familiar. Você pode tratar os objetos TextBlob como se fossem cadeias Python que aprenderam como processar o idioma natural.\n",
    "\n",
    "**ESPECIFICAÇÕES**:\n",
    "\n",
    "A propriedade sentiment retorna uma tupla (polaridade, subjetividade). \n",
    "- POLARITY - é um valor contínuo que varia de -1.0 a 1.0, sendo -1.0 referente a 100% negativo e 1.0 a 100% positivo.\n",
    "- SUBJECTIVITY - que também é um valor contínuo que varia de 0.0 a 1.0, sendo 0.0 referente a 100% objetivo e 1.0 a 100% subjetivo. \n",
    "\n",
    "**apenas em inglês**. \n",
    "\n",
    "- Site oficial: https://textblob.readthedocs.io\n",
    "- Documentação: https://textblob.readthedocs.io/en/dev/quickstart.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Using cached https://files.pythonhosted.org/packages/7c/7d/ad09a26b63d4ad3f9395840c72c95f2fc9fa2b192094ef14e9e720be56f9/textblob-0.15.2-py2.py3-none-any.whl\n",
      "Collecting nltk>=3.1 (from textblob)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/03662232677/anaconda3/envs/pln_ase/lib/python3.6/site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Collecting singledispatch (from nltk>=3.1->textblob)\n",
      "  Using cached https://files.pythonhosted.org/packages/c5/10/369f50bcd4621b263927b0a1519987a04383d4a98fb10438042ad410cf88/singledispatch-3.4.0.3-py2.py3-none-any.whl\n",
      "Installing collected packages: singledispatch, nltk, textblob\n",
      "Successfully installed nltk-3.4 singledispatch-3.4.0.3 textblob-0.15.2\n"
     ]
    }
   ],
   "source": [
    "# Exemplo TextBlob - Passo 1\n",
    "#\n",
    "# Instalando a biblioteca do TextBlob\n",
    "#\n",
    "!pip install --upgrade textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=-0.17777777777777776, subjectivity=0.5708333333333333)\n",
      "Polaridade: -0.17777777777777776\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Exemplo TextBlob - Passo 2\n",
    "#\n",
    "# Realizando uma chamada simples com texto em inglês\n",
    "#\n",
    "from textblob import TextBlob\n",
    "# Definindo um texto a ser analisado\n",
    "sentence = TextBlob('Team, I know that times are tough! Product '\\\n",
    "        'sales have been disappointing for the past three '\\\n",
    "        'quarters. We have a competitive product, but we '\\\n",
    "        'need to do a better job of selling it!')\n",
    "# Imprimindo o resultado da análise\n",
    "print(sentence.sentiment)\n",
    "print('Polaridade: {}'.format(sentence.sentiment.polarity))\n",
    "print('-------------------------------------------------------------')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idioma: pt\n",
      "-------------------------------------------------------------\n",
      "Tradução: The result of the first call of the Unified Selection System (Sisu) was released on Monday (28). To access the approved list, you must enter the program's website. Registration will take place between January 30 and February 4. During this period, candidates will need to gather the required documents and attend the address informed by the educational institution in which they will study.\n",
      "-------------------------------------------------------------\n",
      "Sentiment(polarity=0.25, subjectivity=0.29166666666666663)\n",
      "Polaridade: 0.25\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Exemplo TextBlob - Passo 3\n",
    "#\n",
    "# Traduzindo para o inglês antes de submeter\n",
    "#\n",
    "from textblob import TextBlob\n",
    "# Definindo um texto a ser analisado\n",
    "sentence = TextBlob('O resultado da primeira chamada do Sistema de Seleção Unificada (Sisu) '\\\n",
    "        'foi divulgado nesta segunda-feira (28). Para acessar a lista de aprovados, '\\\n",
    "        'é preciso entrar no site do programa. As matrículas ocorrerão entre 30 de '\\\n",
    "        'janeiro e 4 de fevereiro. Nesse período, os candidatos precisarão reunir '\\\n",
    "        'os documentos exigidos e comparecer ao endereço informado pela instituição de ensino em que estudarão.')\n",
    "# Detectando o idoma e traduzindo para o inglês\n",
    "print('Idioma: {}'.format(sentence.detect_language()))\n",
    "print('-------------------------------------------------------------')\n",
    "sentence = sentence.translate(to='en')\n",
    "print('Tradução: {}'.format(sentence))\n",
    "print('-------------------------------------------------------------')\n",
    "# Imprimindo o resultado da análise\n",
    "print(sentence.sentiment)\n",
    "print('Polaridade: {}'.format(sentence.sentiment.polarity))\n",
    "print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 1\n",
    "\n",
    "Copie e cole a célula acima\n",
    "\n",
    "Busque três textos em português na Internet e salve-os em um arquivo à parte.\n",
    "\n",
    "Para cada um dos textos, substitua a variável original_text pelo texto, execute e anote os resultados no arquivo. Avalie os resultados.\n",
    "\n",
    "Dica: Se o texto for grande, utilize as aspas triplas ''' para separar o texto. Ex: \n",
    "\n",
    "original_text = '''\n",
    "    exemplo de texto\n",
    "    ... \n",
    "    final do texto\n",
    "    '''\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Sentimento com NLTK Vader\n",
    "\n",
    "**APRESENTAÇÃO**:\n",
    "\n",
    "O NLTK vem com um módulo interno de análise de sentimentos - nltk.sentiment.vader - que pode analisar um trecho de texto e classificar as sentenças em polaridade positiva, negativa e neutra de sentimentos. \n",
    "\n",
    "**ESPECIFICAÇÕES**:\n",
    "\n",
    "Provê uma pontuação de intensidade de sentença às sentenças. Retorna no formato \n",
    "- neg: valor de 0 a 1 que representa sentimento negativo\n",
    "- neu: valor de 0 a 1 que representa sentimento neutro\n",
    "- pos: valor de 0 a 1 que representa sentimento positivo\n",
    "- compound: Valor composto pela normalização da soma dos sentimentos do texto \n",
    "\n",
    "**apenas em inglês**. \n",
    "\n",
    "- Site oficial e documentação: http://www.nltk.org/api/nltk.sentiment.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo NLTK Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: nltk in /home/03662232677/anaconda3/envs/pln_ase/lib/python3.6/site-packages (3.4)\r\n",
      "Requirement already satisfied, skipping upgrade: six in /home/03662232677/anaconda3/envs/pln_ase/lib/python3.6/site-packages (from nltk) (1.12.0)\r\n",
      "Requirement already satisfied, skipping upgrade: singledispatch in /home/03662232677/anaconda3/envs/pln_ase/lib/python3.6/site-packages (from nltk) (3.4.0.3)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/03662232677/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans\n",
      "Requirement already satisfied: requests in /home/03662232677/anaconda3/envs/pln_ase/lib/python3.6/site-packages (from googletrans) (2.21.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/03662232677/anaconda3/envs/pln_ase/lib/python3.6/site-packages (from requests->googletrans) (2018.11.29)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/03662232677/anaconda3/envs/pln_ase/lib/python3.6/site-packages (from requests->googletrans) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/03662232677/anaconda3/envs/pln_ase/lib/python3.6/site-packages (from requests->googletrans) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/03662232677/anaconda3/envs/pln_ase/lib/python3.6/site-packages (from requests->googletrans) (1.24.1)\n",
      "Installing collected packages: googletrans\n",
      "Successfully installed googletrans-2.4.0\n"
     ]
    }
   ],
   "source": [
    "# Exemplo NLTK Vader - Passo 1\n",
    "#\n",
    "# Instalando a biblioteca do NLTK, baixando a base léxica do Vader\n",
    "# Baixando também a biblioteca googletrans para fazer tradução com o Google Translate\n",
    "#\n",
    "!pip install --upgrade nltk\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "!pip install googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team, I know that times are tough! Product sales have been disappointing for the past three quarters. We have a competitive product, but we need to do a better job of selling it!\n",
      "-------------------------------------------------------------\n",
      "neg: 0.095, \n",
      "neu: 0.74, \n",
      "pos: 0.165, \n",
      "compound: 0.5321, \n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Exemplo NLTK Vader - Passo 2\n",
    "#\n",
    "# Realizando uma chamada simples com texto em inglês\n",
    "#\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "# Definindo um texto a ser analisado\n",
    "sentence = 'Team, I know that times are tough! Product '\\\n",
    "        'sales have been disappointing for the past three '\\\n",
    "        'quarters. We have a competitive product, but we '\\\n",
    "        'need to do a better job of selling it!'\n",
    "print(sentence)\n",
    "print('-------------------------------------------------------------')\n",
    "# Fazendo a chamada  \n",
    "sid = SentimentIntensityAnalyzer()\n",
    "ss = sid.polarity_scores(sentence)\n",
    "for k in ss:\n",
    "    print('{0}: {1}, '.format(k, ss[k]), end='\\n')\n",
    "print('-------------------------------------------------------------')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tradução: The result of the first call of the Unified Selection System (Sisu) was released on Monday (28). To access the list of approved, you must enter the website of the program. Registration will take place between January 30 and February 4. During this period, candidates will need to gather the required documents and attend the address informed by the educational institution in which they will study.\n",
      "-------------------------------------------------------------\n",
      "neg: 0.039, \n",
      "neu: 0.961, \n",
      "pos: 0.0, \n",
      "compound: -0.296, \n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Exemplo NLTK Vader - Passo 2\n",
    "#\n",
    "# Traduzindo para o inglês antes de submeter\n",
    "#\n",
    "from googletrans import Translator\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "# Definindo um texto a ser analisado\n",
    "sentence = 'O resultado da primeira chamada do Sistema de Seleção Unificada (Sisu) '\\\n",
    "        'foi divulgado nesta segunda-feira (28). Para acessar a lista de aprovados, '\\\n",
    "        'é preciso entrar no site do programa. As matrículas ocorrerão entre 30 de '\\\n",
    "        'janeiro e 4 de fevereiro. Nesse período, os candidatos precisarão reunir '\\\n",
    "        'os documentos exigidos e comparecer ao endereço informado pela instituição de ensino em que estudarão.'\n",
    "translator = Translator()\n",
    "translation = translator.translate(sentence, dest='en').text\n",
    "print('Tradução: {}'.format(translation))\n",
    "print('-------------------------------------------------------------')\n",
    "# Fazendo a chamada  \n",
    "sid = SentimentIntensityAnalyzer()\n",
    "ss = sid.polarity_scores(sentence)\n",
    "for k in ss:\n",
    "    print('{0}: {1}, '.format(k, ss[k]), end='\\n')\n",
    "print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 2\n",
    "\n",
    "Copie e cole a célula acima\n",
    "\n",
    "Utilizando os três textos salvos no Exercício 1, faça:\n",
    "    \n",
    "Para cada um dos textos, substitua a variável original_text pelo texto, execute e anote os resultados no arquivo. \n",
    "\n",
    "Avalie os resultados. Foi melhor ou pior que o TextBlob?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Sentimento com Pattern\n",
    "\n",
    "**APRESENTAÇÃO**:\n",
    "\n",
    "O módulo pattern.en contém um tagger fast-of-speech para o inglês (identifica substantivos, adjetivos, verbos, etc. em uma frase), análise de sentimento, ferramentas para conjugação de verbos em inglês e singularização e pluralização de substantivos e uma interface WordNet.\n",
    "\n",
    "**ESPECIFICAÇÕES**:\n",
    "\n",
    "A função **sentiment()** retorna um parâmetro (polaridade, subjetividade) para a frase dada, com base nos adjetivos que ela contém, onde:\n",
    "- **polaridade** é um valor entre -1,0 e +1,0 \n",
    "- **subjetividade** entre 0,0 e 1,0. \n",
    "\n",
    "A sentença pode ser uma string, texto, frase, pedaço, palavra ou uma sincronia (veja abaixo).\n",
    "\n",
    "A função **positive()** retorna True se a polaridade da sentença dada estiver acima do limite. O limite pode ser reduzido ou aumentado, mas, em geral, o +0.1 fornece os melhores resultados para análises de produtos. A precisão é de cerca de 75% para revisões de filmes.\n",
    "\n",
    "Nota: Existe que esteja instalado o pacote libmysqlclient-dev no Linux\n",
    "\n",
    "**apenas em inglês**. \n",
    "\n",
    "- Site oficial e documentação: https://www.clips.uantwerpen.be/pages/pattern-en#sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pattern\n",
      "Collecting future (from pattern)\n",
      "Collecting backports.csv (from pattern)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/f7/5db9136de67021a6dce4eefbe50d46aa043e59ebb11c83d4ecfeb47b686e/backports.csv-1.0.6-py2.py3-none-any.whl\n",
      "Collecting beautifulsoup4 (from pattern)\n",
      "  Using cached https://files.pythonhosted.org/packages/1d/5d/3260694a59df0ec52f8b4883f5d23b130bc237602a1411fa670eae12351e/beautifulsoup4-4.7.1-py3-none-any.whl\n",
      "Collecting feedparser (from pattern)\n",
      "Requirement already satisfied, skipping upgrade: nltk in /home/03662232677/anaconda3/envs/pln_ase/lib/python3.6/site-packages (from pattern) (3.4)\n",
      "Requirement already satisfied, skipping upgrade: requests in /home/03662232677/anaconda3/envs/pln_ase/lib/python3.6/site-packages (from pattern) (2.21.0)\n",
      "Collecting pdfminer.six (from pattern)\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/fd/6e8746e6965d1a7ea8e97253e3d79e625da5547e8f376f88de5d024bacb9/pdfminer.six-20181108-py2.py3-none-any.whl\n",
      "Collecting scipy (from pattern)\n",
      "  Using cached https://files.pythonhosted.org/packages/67/e6/6d4edaceee6a110ecf6f318482f5229792f143e468b34a631f5a0899f56d/scipy-1.2.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting mysqlclient (from pattern)\n",
      "Collecting python-docx (from pattern)\n",
      "Collecting cherrypy (from pattern)\n",
      "  Using cached https://files.pythonhosted.org/packages/3e/a2/cb5636c76781452bacbdb67d666b787ae560fb180d72eb5f94a891fcc03a/CherryPy-18.1.0-py2.py3-none-any.whl\n",
      "Collecting lxml (from pattern)\n",
      "  Using cached https://files.pythonhosted.org/packages/5d/d4/e81be10be160a6323cf5f29f1eabc9693080cb16780a2e19c96091ee37ee/lxml-4.3.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting numpy (from pattern)\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/74/54c5f9bb9bd4dae27a61ec1b39076a39d359b3fb7ba15da79ef23858a9d8/numpy-1.16.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting soupsieve>=1.2 (from beautifulsoup4->pattern)\n",
      "  Using cached https://files.pythonhosted.org/packages/bf/b3/2473abf05c4950c6a829ed5dcbc40d8b56d4351d15d6939c8ffb7c6b1a14/soupsieve-1.7.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: singledispatch in /home/03662232677/anaconda3/envs/pln_ase/lib/python3.6/site-packages (from nltk->pattern) (3.4.0.3)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/03662232677/anaconda3/envs/pln_ase/lib/python3.6/site-packages (from nltk->pattern) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/03662232677/anaconda3/envs/pln_ase/lib/python3.6/site-packages (from requests->pattern) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /home/03662232677/anaconda3/envs/pln_ase/lib/python3.6/site-packages (from requests->pattern) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /home/03662232677/anaconda3/envs/pln_ase/lib/python3.6/site-packages (from requests->pattern) (1.24.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/03662232677/anaconda3/envs/pln_ase/lib/python3.6/site-packages (from requests->pattern) (2018.11.29)\n",
      "Collecting sortedcontainers (from pdfminer.six->pattern)\n",
      "  Using cached https://files.pythonhosted.org/packages/13/f3/cf85f7c3a2dbd1a515d51e1f1676d971abe41bba6f4ab5443240d9a78e5b/sortedcontainers-2.1.0-py2.py3-none-any.whl\n",
      "Collecting pycryptodome (from pdfminer.six->pattern)\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/cf/4b66bf1ac2484ca39599b4576d681186b61b543c2d2c29f9aa4ba3cc53b5/pycryptodome-3.7.3-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting more-itertools (from cherrypy->pattern)\n",
      "  Using cached https://files.pythonhosted.org/packages/a4/a6/42f17d065bda1fac255db13afc94c93dbfb64393eae37c749b4cb0752fc7/more_itertools-5.0.0-py3-none-any.whl\n",
      "Collecting portend>=2.1.1 (from cherrypy->pattern)\n",
      "  Using cached https://files.pythonhosted.org/packages/81/43/21afd5914b74d4271184ee76f4093b45aa6a580dc6627d72dfc33664c6ac/portend-2.3-py2.py3-none-any.whl\n",
      "Collecting zc.lockfile (from cherrypy->pattern)\n",
      "Collecting cheroot>=6.2.4 (from cherrypy->pattern)\n",
      "  Using cached https://files.pythonhosted.org/packages/89/10/96d1db9062afd476e6d63895dd3e41ced836228f904532bc640106be20ef/cheroot-6.5.4-py2.py3-none-any.whl\n",
      "Collecting tempora>=1.8 (from portend>=2.1.1->cherrypy->pattern)\n",
      "  Using cached https://files.pythonhosted.org/packages/6a/73/22900a52243fdcb2251a10bdb7c6a75fc8d40ab59ec25c01e26823af5126/tempora-1.14-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/03662232677/anaconda3/envs/pln_ase/lib/python3.6/site-packages (from zc.lockfile->cherrypy->pattern) (40.6.3)\n",
      "Collecting backports.functools-lru-cache (from cheroot>=6.2.4->cherrypy->pattern)\n",
      "  Using cached https://files.pythonhosted.org/packages/03/8e/2424c0e65c4a066e28f539364deee49b6451f8fcd4f718fefa50cc3dcf48/backports.functools_lru_cache-1.5-py2.py3-none-any.whl\n",
      "Collecting jaraco.functools>=1.20 (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern)\n",
      "  Using cached https://files.pythonhosted.org/packages/12/a4/3e7366d0f5e75dcad7be88524c8cbd0f3a9fb1db243269550981740c57fe/jaraco.functools-2.0-py2.py3-none-any.whl\n",
      "Collecting pytz (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern)\n",
      "  Using cached https://files.pythonhosted.org/packages/61/28/1d3920e4d1d50b19bc5d24398a7cd85cc7b9a75a490570d5a30c57622d34/pytz-2018.9-py2.py3-none-any.whl\n",
      "Installing collected packages: future, backports.csv, soupsieve, beautifulsoup4, feedparser, sortedcontainers, pycryptodome, pdfminer.six, numpy, scipy, mysqlclient, lxml, python-docx, more-itertools, jaraco.functools, pytz, tempora, portend, zc.lockfile, backports.functools-lru-cache, cheroot, cherrypy, pattern\n",
      "Successfully installed backports.csv-1.0.6 backports.functools-lru-cache-1.5 beautifulsoup4-4.7.1 cheroot-6.5.4 cherrypy-18.1.0 feedparser-5.2.1 future-0.17.1 jaraco.functools-2.0 lxml-4.3.0 more-itertools-5.0.0 mysqlclient-1.4.1 numpy-1.16.0 pattern-3.6 pdfminer.six-20181108 portend-2.3 pycryptodome-3.7.3 python-docx-0.8.10 pytz-2018.9 scipy-1.2.0 sortedcontainers-2.1.0 soupsieve-1.7.3 tempora-1.14 zc.lockfile-1.4\n"
     ]
    }
   ],
   "source": [
    "# Exemplo Pattern - Passo 1\n",
    "#\n",
    "# Instalando a biblioteca do Pattern\n",
    "#\n",
    "# Executar primeiro: \n",
    "#   sudo apt-get install libmysqlclient-dev\n",
    "!pip install --upgrade pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team, I know that times are tough! Product sales have been disappointing for the past three quarters. We have a competitive product, but we need to do a better job of selling it!\n",
      "-------------------------------------------------------------\n",
      "Sentimento: (-0.17777777777777776, 0.5708333333333333)\n",
      "-------------------------------------------------------------\n",
      "Sentimento Positivo: False\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Exemplo Pattern - Passo 2\n",
    "#\n",
    "# Realizando uma chamada simples da função sentiment() com texto em inglês\n",
    "#\n",
    "from pattern.en import sentiment \n",
    "from pattern.en import positive \n",
    "# Definindo um texto a ser analisado\n",
    "sentence = 'Team, I know that times are tough! Product '\\\n",
    "        'sales have been disappointing for the past three '\\\n",
    "        'quarters. We have a competitive product, but we '\\\n",
    "        'need to do a better job of selling it!'\n",
    "print(sentence)\n",
    "print('-------------------------------------------------------------')\n",
    "# Fazendo a chamada de sentiment()\n",
    "print('Sentimento: {}'.format(sentiment(sentence)))\n",
    "print('-------------------------------------------------------------')\n",
    "# Fazendo a chamada de positive()\n",
    "print('Sentimento Positivo: {}'.format(positive(sentence,threshold=0.1)))\n",
    "print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tradução: The result of the first call of the Unified Selection System (Sisu) was released on Monday (28). To access the list of approved, you must enter the website of the program. Registration will take place between January 30 and February 4. During this period, candidates will need to gather the required documents and attend the address informed by the educational institution in which they will study.\n",
      "-------------------------------------------------------------\n",
      "Sentimento: (0.25, 0.29166666666666663)\n",
      "-------------------------------------------------------------\n",
      "Sentimento Positivo: True\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Exemplo Pattern - Passo 3\n",
    "#\n",
    "# Traduzindo para o inglês antes de submeter\n",
    "#\n",
    "from googletrans import Translator\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "# Definindo um texto a ser analisado\n",
    "sentence = 'O resultado da primeira chamada do Sistema de Seleção Unificada (Sisu) '\\\n",
    "        'foi divulgado nesta segunda-feira (28). Para acessar a lista de aprovados, '\\\n",
    "        'é preciso entrar no site do programa. As matrículas ocorrerão entre 30 de '\\\n",
    "        'janeiro e 4 de fevereiro. Nesse período, os candidatos precisarão reunir '\\\n",
    "        'os documentos exigidos e comparecer ao endereço informado pela instituição de ensino em que estudarão.'\n",
    "translator = Translator()\n",
    "translation = translator.translate(sentence, dest='en').text\n",
    "print('Tradução: {}'.format(translation))\n",
    "print('-------------------------------------------------------------')\n",
    "# Fazendo a chamada de sentiment()\n",
    "print('Sentimento: {}'.format(sentiment(translation)))\n",
    "print('-------------------------------------------------------------')\n",
    "# Fazendo a chamada de positive()\n",
    "print('Sentimento Positivo: {}'.format(positive(translation,threshold=0.1)))\n",
    "print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 3\n",
    "\n",
    "Copie e cole a célula acima\n",
    "\n",
    "Utilizando os três textos salvos no Exercício 1, faça:\n",
    "    \n",
    "Para cada um dos textos, substitua a variável original_text pelo texto, execute e anote os resultados no arquivo. \n",
    "\n",
    "Avalie os resultados. Foi melhor ou pior que o TextBlob e NLTK-Vader?\n",
    "\n",
    "E em comparação ao NLU do notebook anterior, qual foi melhor?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
