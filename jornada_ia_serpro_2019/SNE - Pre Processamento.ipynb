{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-Processamento de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import pickle\n",
    "import re\n",
    "from nltk import tokenize # Tokenização\n",
    "from nltk.corpus import stopwords # Stopwords\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports e definição de funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o stemmer\n",
    "stemmer = LancasterStemmer() \n",
    "# Stop words para o Português\n",
    "portuguese_stops = set(stopwords.words('portuguese'))\n",
    "portuguese_stops.update('é')\n",
    "# Lista de palavras para remover com regex\n",
    "include_regex = [r\"^[A-Za-zçãàáâéêíóôõúüÂÃÁÀÉÊÍÓÔÕÚÜÇ'º°ª\\.]*$\",r\"^[0-9\\-/\\\\\\.]*$\"]\n",
    "#include_regex = [r\"^[A-Za-zçãàáâéêíóôõúüÂÃÁÀÉÊÍÓÔÕÚÜÇ'º°ª\\.]*$\"]\n",
    "LIMITE_TAMANHO_PALAVRA = 3\n",
    "# Dicionátio que armazena as pontuações a serem removidas\n",
    "tbl = {} \n",
    "for code in [i for i in range(sys.maxunicode) if unicodedata.category(chr(i)).startswith('P')]:\n",
    "    tbl[code] = ' '\n",
    "# Função para remover pontuações das sentenças\n",
    "def remove_punctuation(text): \n",
    "    return text.translate(tbl)\n",
    "# Função para salvar uma lista em um binário\n",
    "def save_list_to_file(list_to_save,file_name):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(list_to_save, f)\n",
    "# Função para realizar o pré-processamento dos conteúdos dos arquivos\n",
    "def create_doc(txt): \n",
    "    docs = []\n",
    "    ngrs = []\n",
    "    ret = {}\n",
    "    with open(os.path.join('texto_extraido',txt),'r') as f:\n",
    "        content = remove_punctuation(f.read())\n",
    "        words = tokenize.word_tokenize(content, language='portuguese')     \n",
    "        # Remove stopwords\n",
    "        words = [word for word in words if word.lower() not in portuguese_stops] \n",
    "        # Stem de cada palavra, converte para minúsculo \n",
    "        words = [stemmer.stem(w.lower()) for w in words] \n",
    "        # Remove palavras menores que um limite\n",
    "        words = [word for word in words if len(word) > LIMITE_TAMANHO_PALAVRA] \n",
    "        # Remove regex words\n",
    "        words_aux = []\n",
    "        for word in words:\n",
    "            add = False\n",
    "            for regex_exp in include_regex:\n",
    "                if re.compile(regex_exp).match(word):\n",
    "                    add = True\n",
    "            if add:\n",
    "                words_aux.append(word)\n",
    "            #else:\n",
    "            #    print ('removerndo regex: ',word)\n",
    "        words = words_aux\n",
    "        for ngr in ngrams(words,2):\n",
    "            ngrs.append(ngr)\n",
    "        ret['ngrams'] = ngrs\n",
    "        # Busca resultados e adiciona nos docs\n",
    "        reg = df.loc[df['Nome do Arquivo'].str.contains(os.path.splitext(txt)[0])] # Busca o resultado do arquivo \n",
    "        cats = []\n",
    "        for cat in categories:\n",
    "            if not reg[cat].isnull().values[0]:\n",
    "                # Uma lista de tuplas com as palavras das sentenças e o nome da categoria\n",
    "                cats.append(cat)\n",
    "        docs.append((ngrs, cats, txt))\n",
    "    ret['docs'] = docs\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importanto os documentos e planilha e pré-processando o texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  arquivos processados. Último processado:  148494751_1_OCR.txt\n",
      "200  arquivos processados. Último processado:  147672969_1_OCR.txt\n",
      "300  arquivos processados. Último processado:  146626769_1_OCR.txt\n",
      "400  arquivos processados. Último processado:  146594538_1_OCR.txt\n",
      "500  arquivos processados. Último processado:  143667061_1_OCR.txt\n",
      "600  arquivos processados. Último processado:  148623718_1_OCR.txt\n",
      "700  arquivos processados. Último processado:  146509336_1_OCR.txt\n",
      "800  arquivos processados. Último processado:  147130806_1_OCR.txt\n",
      "900  arquivos processados. Último processado:  148796460_1_OCR.txt\n",
      "1000  arquivos processados. Último processado:  146882472_1_OCR.txt\n",
      "1100  arquivos processados. Último processado:  146660219_1_OCR.txt\n",
      "1200  arquivos processados. Último processado:  146437513_1_OCR.txt\n",
      "1300  arquivos processados. Último processado:  147726641_1_OCR.txt\n",
      "1400  arquivos processados. Último processado:  150639780_1_OCR.txt\n",
      "1500  arquivos processados. Último processado:  147748486_1_OCR.txt\n",
      "1577  arquivos processados. Último processado:  146417074_1_OCR.txt\n",
      "\n",
      "Foram geradas  1577  combinações e  1413062  palavras\n",
      "\n",
      " 11 Categorias:  ['atx_precricao', 'atx_decadencia', 'atx_jurisprudencia', 'atx_duplavisita', 'atx_criteriojuridico', 'atx_atenuacao', 'atx_principios', 'atx_retroatividade', 'atx_nulidade', 'atx_intimprevia', 'atx_denuncia_espontanea']\n",
      "\n",
      " 1577 Docs (primeiro):  [([('empres', 'acim'), ('acim', 'entregou'), ('entregou', 'espontanea'), ('espontanea', 'atraso'), ('atraso', 'gfip'), ('gfip', 'competência'), ('competência', '2010'), ('2010', '2010'), ('2010', 'receit'), ('receit', 'brasil'), ('brasil', 'multou'), ('multou', 'mesm'), ('mesm', 'const'), ('const', 'auto'), ('auto', 'infração'), ('infração', 'pedindo'), ('pedindo', 'impugnação'), ('impugnação', 'pagamento'), ('pagamento', 'desconto'), ('desconto', 'mesm'), ('mesm', 'trint'), ('trint', 'direito'), ('direito', 'prelimin'), ('prelimin', 'viemo'), ('viemo', 'atravé'), ('atravé', 'dest'), ('dest', 'solicit'), ('solicit', 'impugnação'), ('impugnação', 'auto'), ('auto', 'infração'), ('infração', 'declaração'), ('declaração', 'entregu'), ('entregu', 'notificação'), ('notificação', 'pedindo'), ('pedindo', 'mesm'), ('mesm', 'enviad'), ('enviad', 'guia'), ('guia', 'constam'), ('constam', 'mesm'), ('mesm', 'recolhida'), ('recolhida', 'conformidad'), ('conformidad', 'dado'), ('dado', 'declarado'), ('declarado', 'gfip'), ('gfip', 'anexo'), ('anexo', 'cópia'), ('cópia', 'declaraçõ'), ('declaraçõ', 'guia'), ('guia', 'mérito'), ('mérito', 'inciso'), ('inciso', 'outubro'), ('outubro', '1966'), ('1966', 'responsabilidad'), ('responsabilidad', 'excluíd'), ('excluíd', 'denúnc'), ('denúnc', 'espontâne'), ('espontâne', 'infração'), ('infração', 'acompanhad'), ('acompanhad', 'caso'), ('caso', 'pagamento'), ('pagamento', 'tributo'), ('tributo', 'devido'), ('devido', 'juro'), ('juro', 'depósito'), ('depósito', 'importânc'), ('importânc', 'arbitrad'), ('arbitrad', 'autoridad'), ('autoridad', 'administrativ'), ('administrativ', 'mont'), ('mont', 'tributo'), ('tributo', 'depend'), ('depend', 'apuração'), ('apuração', 'parágrafo'), ('parágrafo', 'único'), ('único', 'consider'), ('consider', 'espontâne'), ('espontâne', 'denúnc'), ('denúnc', 'apresentad'), ('apresentad', 'início'), ('início', 'qualqu'), ('qualqu', 'procedimento'), ('procedimento', 'administrativo'), ('administrativo', 'medid'), ('medid', 'fiscalização'), ('fiscalização', 'relacionado'), ('relacionado', 'infração'), ('infração', 'instrução'), ('instrução', 'normativ'), ('normativ', 'novembro'), ('novembro', '2009'), ('2009', 'caso'), ('caso', 'denúnc'), ('denúnc', 'espontâne'), ('espontâne', 'infração'), ('infração', 'lavratur'), ('lavratur', 'auto'), ('auto', 'infração'), ('infração', 'aplicação'), ('aplicação', 'penalidad'), ('penalidad', 'descumprimento'), ('descumprimento', 'obrigação'), ('obrigação', 'acessór'), ('acessór', 'parágrafo'), ('parágrafo', 'único'), ('único', 'consider'), ('consider', 'denúnc'), ('denúnc', 'espontâne'), ('espontâne', 'procedimento'), ('procedimento', 'adotado'), ('adotado', 'infr'), ('infr', 'regul'), ('regul', 'situação'), ('situação', 'configurado'), ('configurado', 'infração'), ('infração', 'início'), ('início', 'qualqu'), ('qualqu', 'ação'), ('ação', 'fisc'), ('fisc', 'relacionad'), ('relacionad', 'infração'), ('infração', 'dispensad'), ('dispensad', 'comunicação'), ('comunicação', 'correção'), ('correção', 'falt'), ('falt', 'conclusão'), ('conclusão', 'vist'), ('vist', 'todo'), ('todo', 'exposto'), ('exposto', 'demonstrad'), ('demonstrad', 'insubsistênc'), ('insubsistênc', 'improcedênc'), ('improcedênc', 'ação'), ('ação', 'fisc'), ('fisc', 'esper'), ('esper', 'requ'), ('requ', 'impugn'), ('impugn', 'acolhid'), ('acolhid', 'pres'), ('pres', 'impugnação'), ('impugnação', 'decidido'), ('decidido', 'cancelando'), ('cancelando', 'débito'), ('débito', 'fisc'), ('fisc', 'reclamado'), ('reclamado', 'termo')], ['atx_intimprevia', 'atx_denuncia_espontanea'], '147087145_1_OCR.txt')]\n",
      "\n",
      " 1413062  N-Grams:  [('empres', 'acim'), ('acim', 'entregou'), ('entregou', 'espontanea'), ('espontanea', 'atraso'), ('atraso', 'gfip'), ('gfip', 'competência'), ('competência', '2010'), ('2010', '2010'), ('2010', 'receit'), ('receit', 'brasil'), ('brasil', 'multou'), ('multou', 'mesm'), ('mesm', 'const'), ('const', 'auto'), ('auto', 'infração'), ('infração', 'pedindo'), ('pedindo', 'impugnação'), ('impugnação', 'pagamento'), ('pagamento', 'desconto'), ('desconto', 'mesm'), ('mesm', 'trint'), ('trint', 'direito'), ('direito', 'prelimin'), ('prelimin', 'viemo'), ('viemo', 'atravé'), ('atravé', 'dest'), ('dest', 'solicit'), ('solicit', 'impugnação'), ('impugnação', 'auto'), ('auto', 'infração'), ('infração', 'declaração'), ('declaração', 'entregu'), ('entregu', 'notificação'), ('notificação', 'pedindo'), ('pedindo', 'mesm'), ('mesm', 'enviad'), ('enviad', 'guia'), ('guia', 'constam'), ('constam', 'mesm'), ('mesm', 'recolhida'), ('recolhida', 'conformidad'), ('conformidad', 'dado'), ('dado', 'declarado'), ('declarado', 'gfip'), ('gfip', 'anexo'), ('anexo', 'cópia'), ('cópia', 'declaraçõ'), ('declaraçõ', 'guia'), ('guia', 'mérito'), ('mérito', 'inciso'), ('inciso', 'outubro'), ('outubro', '1966'), ('1966', 'responsabilidad'), ('responsabilidad', 'excluíd'), ('excluíd', 'denúnc'), ('denúnc', 'espontâne'), ('espontâne', 'infração'), ('infração', 'acompanhad'), ('acompanhad', 'caso'), ('caso', 'pagamento'), ('pagamento', 'tributo'), ('tributo', 'devido'), ('devido', 'juro'), ('juro', 'depósito'), ('depósito', 'importânc'), ('importânc', 'arbitrad'), ('arbitrad', 'autoridad'), ('autoridad', 'administrativ'), ('administrativ', 'mont'), ('mont', 'tributo'), ('tributo', 'depend'), ('depend', 'apuração'), ('apuração', 'parágrafo'), ('parágrafo', 'único'), ('único', 'consider'), ('consider', 'espontâne'), ('espontâne', 'denúnc'), ('denúnc', 'apresentad'), ('apresentad', 'início'), ('início', 'qualqu'), ('qualqu', 'procedimento'), ('procedimento', 'administrativo'), ('administrativo', 'medid'), ('medid', 'fiscalização'), ('fiscalização', 'relacionado'), ('relacionado', 'infração'), ('infração', 'instrução'), ('instrução', 'normativ'), ('normativ', 'novembro'), ('novembro', '2009'), ('2009', 'caso'), ('caso', 'denúnc'), ('denúnc', 'espontâne'), ('espontâne', 'infração'), ('infração', 'lavratur'), ('lavratur', 'auto'), ('auto', 'infração'), ('infração', 'aplicação'), ('aplicação', 'penalidad'), ('penalidad', 'descumprimento')]\n"
     ]
    }
   ],
   "source": [
    "# Importando a planilha com os dados de treinamento no formato CSV\n",
    "df = pd.read_csv('resultwex2.csv') \n",
    "# Gera uma lista com todas as categorias de classificação a partir do CSV\n",
    "categories = list(df.columns[2:13])\n",
    "# Lista de todas as palavras de todos os documentos\n",
    "all_ngrams = []\n",
    "# Uma lista de tuplas com as palavras das sentenças e o nome da categoria\n",
    "docs = [] \n",
    "ngr = []\n",
    "list_txt = os.listdir(\"texto_extraido\")\n",
    "count = 0\n",
    "LIMITE = -1\n",
    "for txt in list_txt:\n",
    "    count += 1\n",
    "    ret = create_doc(txt)\n",
    "    docs.extend(ret['docs'])\n",
    "    all_ngrams.extend(ret['ngrams'])\n",
    "    if count % 100 == 0:\n",
    "        print (count,' arquivos processados. Último processado: ',txt)\n",
    "    if LIMITE != -1 and count == LIMITE:\n",
    "        break\n",
    "print (count,' arquivos processados. Último processado: ',txt)\n",
    "print('\\nForam geradas ',len(docs),' combinações e ',len(all_ngrams),' palavras')\n",
    "print ('\\n',len(categories),'Categorias: ',categories)\n",
    "print ('\\n',len(docs),'Docs (primeiro): ',docs[:1])\n",
    "print ('\\n',len(all_ngrams),' N-Grams: ',all_ngrams[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando os arquivos para uso posterior em outro programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos salvos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Store data (serialize)\n",
    "save_list_to_file(categories,'categories.pickle')\n",
    "save_list_to_file(all_ngrams,'all_ngrams.pickle')\n",
    "save_list_to_file(docs,'docs.pickle')\n",
    "print ('Arquivos salvos com sucesso!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
